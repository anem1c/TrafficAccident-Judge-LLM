{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dotenv import load_dotenv\n",
    "import os\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langchain_core.messages import HumanMessage\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "#모델 설정\n",
    "model = ChatOpenAI(model=\"gpt-4o-mini\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# FAISS 벡터 스토어 로드\n",
    "from langchain_community.vectorstores import FAISS\n",
    "from langchain_openai import OpenAIEmbeddings\n",
    "\n",
    "# 동일한 임베딩 모델 초기화 (FAISS 로드 시 필요)\n",
    "embeddings = OpenAIEmbeddings(model=\"text-embedding-ada-002\")\n",
    "\n",
    "# 로컬에서 로드\n",
    "vector_store_law = FAISS.load_local(\n",
    "    'vector_store_law', embeddings, allow_dangerous_deserialization=True)\n",
    "vector_store_situation = FAISS.load_local(\n",
    "    'vector_store_situation', embeddings, allow_dangerous_deserialization=True)\n",
    "vector_store_rate = FAISS.load_local(\n",
    "    'vector_store_rate', embeddings, allow_dangerous_deserialization=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 유사성 검색 리트리버 정의\n",
    "retriever = vector_store_law.as_retriever(\n",
    "    search_type=\"similarity\", search_kwargs={\"k\": 5})\n",
    "\n",
    "retriever1 = vector_store_situation.as_retriever(\n",
    "    search_type=\"similarity\", search_kwargs={\"k\": 1})\n",
    "\n",
    "retriever2 = vector_store_rate.as_retriever(\n",
    "    search_type=\"similarity\", search_kwargs={\"k\": 1})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain_core.runnables import RunnablePassthrough\n",
    "\n",
    "# 프롬프트 템플릿 정의\n",
    "contextual_prompt = ChatPromptTemplate.from_messages([\n",
    "    (\"system\", '''\n",
    "귀하는 교통사고 과실 비율을 판단하는 챗봇입니다.\n",
    "다음으로 제공되는 context는 사용자 입력 상황과 연관된 법률이며, 이 법률을 근거로 하여 과실 비율을 판단하세요. \n",
    "    context1은 비슷한 사고에 관한 법원의 \"판결문\"이므로 사고 과실 비율 판단에 참고하세요.\n",
    "    또한, context2는 비슷한 사고에 관한 법원에서 인정된 \"과실 비율\"입니다. 사고 상황에 대한 비율만 나와있을 뿐 어떤 누가 어떤 과실인지는 나와있지 않으니\n",
    "    벏률을 기반으로 내린 판단과 함께 Question에 대한 과실 비율 판단에 참고하세요.\n",
    "\n",
    "\n",
    "준수해야 할 규칙:\n",
    "1. 사용자가 입력한 사고 상황을 이해한 후, 이해한 상황을 사용자에게 안내하세요.\n",
    "2. 제공된 법률을 근거로 하여 판단해야 합니다.\n",
    "3. 판결 결과를 안내하면서 동시에 실제 판레도 같이 언급하세요. (되도록 context1의 법원의 판단, context2의 과실 비율 모두 언급하세요.)\n",
    "4. 판단이 올바르지 않을 가능성이 있으므로 전문가와 상의하여 보다 상세하고 신뢰할 수 있는 판단을 내릴 수 있도록 안내해 주시기 바랍니다.\n",
    "5. 판단을 내려야 할 상황에서 사용자의 입장이 불확실하다면 반드시 사용자에게 확인하세요.\n",
    "6. 주어진 상황에 관련된 법률에 대한 정보가 없다면 모른다고 대답하세요.\n",
    "7. 만일 context2의 사고 상황이 입력된 사고 상황과 유사하지 않다고 판단된다면, 관련 사례가 없음을 안내한 뒤 context1의 판결문을 참고해 과실 비율을 판단하세요.\n",
    "8. 응답을 시작할 때, 사고 상황을 겪은 사용자를 위로해주는 말로 대화를 시작하세요.\n",
    "9. context2의 과실 비율에는 가해자와 피해자가 나뉘어있지 않으니, 입력된 상황에 대해 더 과실이 큰 대상을 판단한 뒤 그 대상에게 더 큰 과실 비율을 부여하세요.\n",
    "    \n",
    "주의할 규칙:\n",
    "1. 사고 상황에 대해 정리할 때에는 반드시 question의 내용으로만 정리하세요.\n",
    "2. 과실 비율에 대해 판단 할 때에는 기본적으로 context1과 context2의 정보 모두 \"참고\"하세요. (상황이 유사하지 않은 경우, 정보 없는 경우와 같은 부득이한 경우 제외)\n",
    "3. context, context1, context2, question이라는 단어 자체를 언급하지 마세요.\n",
    "4. 청구인, 피청구인이라는 표현을 자제하고 입력된 상황에서의 입장으로 안내하세요. (예시: 후진한 차량은 90%, 직진한 차량은 10%로 판단됩니다.)\n",
    "\n",
    "예시 응답:\n",
    "- \"제공된 사고 상황에서 귀하께선 어떠한 입장이십니까?\"\n",
    "- \"사고 상황 : 고속도로에서 갑작스럽게 후진으로 인한 사고\n",
    "\n",
    "    가능한 과실 비율 : 귀하의 경우에는 고속도로에서 갑작스럽게 후진하셨으므로 과실 비율은 1 : 9로 귀하가 최대 1,000,000원의 합의금을 내야할 수 있습니다.\n",
    "\n",
    "    실제 판례 : [상황] 고속도로에서의 후진으로 인한 사고 [청구인의 과실 비율] 10% [피청구인의 과실 비율] 90%\"\n",
    "\n",
    "\n",
    "- \"죄송합니다. 사고와 관련된 법률에 대한 정보가 없기 때문에 판단이 불가능합니다.\"\n",
    "    \n",
    "응답 형태:\n",
    "    \n",
    "    '''),\n",
    "    (\"user\",\n",
    "    \"Context: {context}\\\\n\\\\Context1: {context1}\\\\n\\\\Context2: {context2}\\\\n\\\\nQuestion: {question}\")\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.chains import LLMChain\n",
    "\n",
    "\n",
    "class SimplePassThrough:\n",
    "    def invoke(self, inputs, **kwargs):\n",
    "        return inputs\n",
    "\n",
    "\n",
    "class ContextToPrompt:\n",
    "    def __init__(self, prompt_template):\n",
    "        self.prompt_template = prompt_template\n",
    "\n",
    "    def invoke(self, inputs):\n",
    "        # 문서 내용을 텍스트로 변환\n",
    "        if isinstance(inputs, list):\n",
    "            context_text = \"\\n\".join([doc.page_content for doc in inputs])\n",
    "        else:\n",
    "            context_text = inputs\n",
    "\n",
    "        # 프롬프트 템플릿에 적용\n",
    "        formatted_prompt = self.prompt_template.format_messages(\n",
    "            context=context_text,\n",
    "            question=inputs.get(\"question\", \"\")\n",
    "        )\n",
    "        return formatted_prompt\n",
    "\n",
    "# Retriever를 invoke() 메서드로 래핑하는 클래스 정의\n",
    "class RetrieverWrapper:\n",
    "    def __init__(self, retriever):\n",
    "        self.retriever = retriever\n",
    "\n",
    "    def invoke(self, inputs):\n",
    "        if isinstance(inputs, dict):\n",
    "            query = inputs.get(\"question\", \"\")\n",
    "        else:\n",
    "            query = inputs\n",
    "        # 검색 수행\n",
    "        response_docs = self.retriever.get_relevant_documents(query)\n",
    "        return response_docs\n",
    "\n",
    "# RAG 체인 구성\n",
    "rag_chain_debug = {\n",
    "    \"context\" : RetrieverWrapper(retriever),\n",
    "    \"context1\": RetrieverWrapper(retriever1),\n",
    "    'context2': RetrieverWrapper(retriever2),\n",
    "    \"prompt\": ContextToPrompt(contextual_prompt),\n",
    "    \"llm\": model\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 비슷한 상황에서 판결된 과실 비율 문서 검색\n",
    "from difflib import SequenceMatcher\n",
    "\n",
    "\n",
    "def find_most_similar_doc(user_accident):\n",
    "    \"\"\"\n",
    "    사용자가 제공한 사고 정보와 가장 유사한 문서를 FAISS 벡터 스토어에서 검색합니다.\n",
    "\n",
    "    Args:\n",
    "        user_accident (str): 사용자가 입력한 사고 상황 텍스트.\n",
    "        vector_store (FAISS): FAISS 벡터 스토어 객체.\n",
    "        embeddings (OpenAIEmbeddings): 임베딩 모델 객체.\n",
    "\n",
    "    Returns:\n",
    "        dict: 가장 유사한 문서의 정보 (텍스트와 메타데이터).\n",
    "    \"\"\"\n",
    "    # 사용자 입력 텍스트의 임베딩 계산\n",
    "    query_embedding = embeddings.embed_query(user_accident)\n",
    "\n",
    "    # 벡터 DB에서 유사한 문서 검색\n",
    "    search_results = vector_store_rate.similarity_search_by_vector(\n",
    "        query_embedding, k=1)\n",
    "\n",
    "    # 결과 반환 (가장 유사한 문서 1개)\n",
    "    if search_results:\n",
    "        return search_results[0]  # 첫 번째 결과 반환\n",
    "    else:\n",
    "        return None  # 검색 결과가 없을 경우"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "========================\n",
      "\n",
      "답변:\n",
      "사고를 겪으신 것에 대해 안타깝게 생각합니다. 주어진 상황을 정리해보면, 점선에서 차선 변경을 하다가 해당 차선의 차량과 충돌한 사고입니다.\n",
      "\n",
      "과실 비율에 대한 판단은 다음과 같습니다. 차선 변경을 하는 차량이 안전거리 확보나 방향지시등을 작동하지 않고 갑작스럽게 차선 변경을 하여 충돌한 경우, 후행차량은 이를 예측하거나 회피하기 어려운 상황이 발생할 수 있습니다. 따라서 차선 변경을 한 차량의 과실이 크게 인정될 수 있습니다. \n",
      "\n",
      "실제 판례를 참고하면, 유사한 사례에서 차선 변경을 한 차량이 상당한 과실을 인정받았다는 점을 고려할 때, 이번 사고에서도 차선 변경을 한 차량의 과실 비율이 70%로, 해당 차량과 충돌한 차량의 과실 비율은 30%로 판단할 수 있습니다. \n",
      "\n",
      "전문가와 상의하여 보다 상세하고 신뢰할 수 있는 판단을 내리시는 것이 좋습니다.\n",
      "========================\n",
      "RAG 실행을 종료합니다.\n"
     ]
    }
   ],
   "source": [
    "# 챗봇 구동\n",
    "query = ''\n",
    "while True:\n",
    "    print(\"========================\")\n",
    "    query = input(\"질문을 입력하세요 : \")\n",
    "\n",
    "    if query == 'stop':\n",
    "        print(\"RAG 실행을 종료합니다.\")\n",
    "        break\n",
    "\n",
    "\n",
    "    # 1. Retriever로 관련 법률 검색\n",
    "    response_docs = rag_chain_debug[\"context\"].invoke({\"question\": query})\n",
    "\n",
    "    # 1-1. Retriever로 관련 상황 문서 검색\n",
    "    response_docs1 = rag_chain_debug[\"context1\"].invoke({\"question\": query})\n",
    "\n",
    "    # 1-2. 관련 문서와 관련된 과실 비율 문서 검색\n",
    "    response_docs2 = find_most_similar_doc(response_docs1[0].metadata['summary'].content)\n",
    "\n",
    "    # 2. 문서를 프롬프트로 변환\n",
    "    prompt_messages = contextual_prompt.format_messages(\n",
    "        context=response_docs[0].page_content,\n",
    "        context1=response_docs1[0].page_content,\n",
    "        context2=response_docs2.page_content,\n",
    "        question=query\n",
    "    )\n",
    "\n",
    "    # 3. LLM으로 응답 생성\n",
    "    response = rag_chain_debug[\"llm\"].invoke(prompt_messages)\n",
    "\n",
    "    print(\"\\n답변:\")\n",
    "    print(response.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "========================\n",
      "\n",
      "답변:\n",
      "사고를 겪으신 것에 대해 안타깝게 생각합니다. 상황을 정리해보면, 귀하께서는 갑자기 튀어나온 무단횡단 보행자와 충돌한 사고를 겪으신 것으로 이해했습니다.\n",
      "\n",
      "이 경우, 보행자는 도로 외의 장소에서 횡단 중일 가능성이 있지만, 보행자가 무단횡단을 한 점과 차량의 전방 주시 의무를 고려해야 합니다. 제공된 정보에 따르면, 보행자의 기본 과실비율은 0%로 설정되어 있으나, 보행자가 갑자기 튀어나온 경우에는 보행자의 중대한 과실이 인정될 수 있으며, 이 경우 과실 비율이 10% 또는 더 높게 가산될 수 있습니다.\n",
      "\n",
      "따라서 귀하의 경우에는 차량 운전자의 과실이 90% 정도로 판단되며, 보행자의 과실은 10%로 평가할 수 있습니다. \n",
      "\n",
      "실제 판례에서는 고속도로에서 비슷한 사고가 발생했을 때, 운전자의 과실이 50%로 평가된 사례가 있음을 참고하시기 바랍니다. \n",
      "\n",
      "결론적으로, 귀하의 경우 과실 비율은 다음과 같이 판단됩니다: \n",
      "- 귀하의 과실: 90%\n",
      "- 보행자의 과실: 10%\n",
      "\n",
      "보다 정확한 판단을 원하신다면 전문가와 상담하시기를 권장드립니다.\n",
      "========================\n",
      "RAG 실행을 종료합니다.\n"
     ]
    }
   ],
   "source": [
    "# 챗봇 구동\n",
    "query = ''\n",
    "while True:\n",
    "    print(\"========================\")\n",
    "    query = input(\"질문을 입력하세요 : \")\n",
    "\n",
    "    if query == 'stop':\n",
    "        print(\"RAG 실행을 종료합니다.\")\n",
    "        break\n",
    "\n",
    "    # 1. Retriever로 관련 법률 검색\n",
    "    response_docs = rag_chain_debug[\"context\"].invoke({\"question\": query})\n",
    "\n",
    "    # 1-1. Retriever로 관련 상황 문서 검색\n",
    "    response_docs1 = rag_chain_debug[\"context1\"].invoke({\"question\": query})\n",
    "\n",
    "    # 1-2. 관련 문서와 관련된 과실 비율 문서 검색\n",
    "    response_docs2 = find_most_similar_doc(\n",
    "        response_docs1[0].metadata['summary'].content)\n",
    "\n",
    "    # 2. 문서를 프롬프트로 변환\n",
    "    prompt_messages = contextual_prompt.format_messages(\n",
    "        context=response_docs[0].page_content,\n",
    "        context1=response_docs1[0].page_content,\n",
    "        context2=response_docs2.page_content,\n",
    "        question=query\n",
    "    )\n",
    "\n",
    "    # 3. LLM으로 응답 생성\n",
    "    response = rag_chain_debug[\"llm\"].invoke(prompt_messages)\n",
    "\n",
    "    print(\"\\n답변:\")\n",
    "    print(response.content)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "faiss_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
