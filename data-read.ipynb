{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dotenv import load_dotenv\n",
    "import os\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langchain_core.messages import HumanMessage\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "#모델 설정\n",
    "model = ChatOpenAI(model=\"gpt-4o-mini\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "파일 '2013가합15831_판결문_검수완료.pdf'에서 텍스트 추출이 없습니다.\n",
      "총 125개의 PDF 파일에서 텍스트를 추출했습니다.\n"
     ]
    }
   ],
   "source": [
    "import pdfplumber\n",
    "import os\n",
    "from langchain.schema import Document\n",
    "\n",
    "# PDF에서 텍스트 추출\n",
    "docs = []\n",
    "\n",
    "# 폴더 내 파일 가져오기\n",
    "path = '교통과산재데이터/'\n",
    "file_list = os.listdir(path)\n",
    "\n",
    "for doc_num, file_name in enumerate(file_list):\n",
    "    file_path = os.path.join(path, file_name)\n",
    "    try:\n",
    "        extracted_text = \"\"  # PDF 한 파일의 전체 텍스트를 저장할 변수\n",
    "        with pdfplumber.open(file_path) as pdf_file:\n",
    "            for i, page in enumerate(pdf_file.pages):\n",
    "                try:\n",
    "                    # 텍스트 추출\n",
    "                    text = page.extract_text()\n",
    "                    if text:\n",
    "                        extracted_text += text + \"\\n\"  # 각 페이지의 텍스트를 합침\n",
    "                except Exception as e:\n",
    "                    print(f\"페이지 {i + 1}에서 오류 발생: {e}\")\n",
    "\n",
    "        # 한 PDF 파일의 전체 텍스트를 하나의 Document로 저장\n",
    "        if extracted_text.strip():  # 추출된 텍스트가 있으면 저장\n",
    "            document = Document(\n",
    "                page_content=extracted_text,\n",
    "                metadata={\"doc_number\": doc_num + 1, \"file_name\": file_name}\n",
    "            )\n",
    "            docs.append(document)\n",
    "        else:\n",
    "            print(f\"파일 '{file_name}'에서 텍스트 추출이 없습니다.\")\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"파일 '{file_name}'에서 오류 발생: {e}\")\n",
    "\n",
    "# 텍스트 추출 결과 확인\n",
    "print(f\"총 {len(docs)}개의 PDF 파일에서 텍스트를 추출했습니다.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "본 판결문은 판결서 인터넷열람 사이트에서 열람·출력되었습니다.\n",
      "영리목적으로 이용하거나 무단 배포를 금합니다.게시일자 : 2016-10-07\n",
      "본 판결문은 판결서 인터넷열람 사이트에서 열람·출력되었습니다.\n",
      "영리목적으로 이용하거나 무단 배포를 금합니다.게시일자 : 2016-10-07\n",
      "본 판결문은 판결서 인터넷열람 사이트에서 열람·출력되었습니다.\n",
      "영리목적으로 이용하거나 무단 배포를 금합니다.게시일자 : 2016-10-07\n",
      "본 판결문은 판결서 인터넷열람 사이트에서 열람·출력되었습니다.\n",
      "영리목적으로 이용하거나 무단 배포를 금합니다.게시일자 : 2016-10-07\n",
      "본 판결문은 판결서 인터넷열람 사이트에서 열람·출력되었습니다.\n",
      "영리목적으로 이용하거나 무단 배포를 금합니다.게시일자 : 2016-10-07\n",
      "본 판결문은 판결서 인터넷열람 사이트에서 열람·출력되었습니다.\n",
      "영리목적으로 이용하거나 무단 배포를 금합니다.게시일자 : 2016-10-07\n",
      "본 판결문은 판결서 인터넷열람 사이트에서 열람·출력되었습니다.\n",
      "영리목적으로 이용하거나 무단 배포를 금합니다.게시일자 : 2016-10-07\n",
      "본 판결문은 판결서 인터넷열람 사이트에서 열람·출력되었습니다.\n",
      "영리목적으로 이용하거나 무단 배포를 금합니다.게시일자 : 2016-10-07\n",
      "본 판결문은 판결서 인터넷열람 사이트에서 열람·출력되었습니다.\n",
      "영리목적으로 이용하거나 무단 배포를 금합니다.게시일자 : 2016-10-07\n",
      "본 판결문은 판결서 인터넷열람 사이트에서 열람·출력되었습니다.\n",
      "영리목적으로 이용하거나 무단 배포를 금합니다.게시일자 : 2016-10-07\n",
      "본 판결문은 판결서 인터넷열람 사이트에서 열람·출력되었습니다.\n",
      "영리목적으로 이용하거나 무단 배포를 금합니다.게시일자 : 2016-10-07\n",
      "본 판결문은 판결서 인터넷열람 사이트에서 열람·출력되었습니다.\n",
      "영리목적으로 이용하거나 무단 배포를 금합니다.게시일자 : 2016-10-07\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# 이미지로 처리되어 내용이 없는 파일 삭제\n",
    "print(docs[0].page_content)\n",
    "\n",
    "docs = docs[1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "# 과실 비율 데이터 읽어오기\n",
    "# 폴더 내에 있는 파일 모두 가져오기\n",
    "with open('accident_data_all_pages.json', 'r', encoding='utf-8') as f:\n",
    "    file = json.load(f)\n",
    "\n",
    "\n",
    "# JSON 데이터를 Document로 변환\n",
    "def nested_json_to_documents(json_data):\n",
    "    docs = []  # 문서 리스트 초기화\n",
    "    # 중첩된 리스트를 순회하며 평탄화\n",
    "    for entry in json_data:  # 최상위 리스트 순회\n",
    "        content = (\n",
    "            f\"상황: {entry['상황']}\\n\"\n",
    "            f\"청구인 과실 비율: {entry['청구인 과실 비율']}\\n\"\n",
    "            f\"피청구인 과실 비율: {entry['피청구인 과실 비율']}\\n\"\n",
    "        )\n",
    "        docs.append(Document(page_content=content))  # Document 객체 추가\n",
    "    return docs\n",
    "\n",
    "docs_rate = nested_json_to_documents(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "\n",
    "# 사고 상황 요약을 위한 프롬프트 템플릿 정의\n",
    "summary_prompt = ChatPromptTemplate.from_messages([\n",
    "    ('system', '주어진 문서 내의 \"교통사고 발생 상황\"을 \"사고 원인\"을 포함해서 한 문장으로 요약해줘. 단순 사고 상황에 대한 내용만 다루고 사건에 대한 판결의 내용은 넣지 말아줘.'),\n",
    "    ('user', '{content}')\n",
    "])\n",
    "\n",
    "# 사고 상황을 요약하는 함수 (LLM 모델 사용)\n",
    "def summarize_accident(accident_text):\n",
    "    summary = summary_prompt.format_messages(content=accident_text)\n",
    "    result = model.invoke(summary)\n",
    "    return result  # 요약된 사고 상황 반환\n",
    "\n",
    "\n",
    "# 문서 요약본 새 document로 저장\n",
    "def summary_docs(original_doc, summary_text):\n",
    "    updated_doc = Document(\n",
    "        metadata={**original_doc.metadata, 'summary': summary_text},  # 요약 추가\n",
    "        page_content=original_doc.page_content,\n",
    "    )\n",
    "    return updated_doc\n",
    "\n",
    "\n",
    "# 요약된 문서들을 저장할 리스트\n",
    "summarized_docs = []\n",
    "\n",
    "# 모든 문서에 대해 요약 생성, 저장 및 임베딩\n",
    "for i in range(len(docs)):\n",
    "    summary = summarize_accident(docs[i].page_content)  # 요약 생성\n",
    "    sum_doc = summary_docs(docs[i], summary)  # 요약 추가\n",
    "    summarized_docs.append(sum_doc)  # 리스트에 추가"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_openai import OpenAIEmbeddings\n",
    "import faiss\n",
    "from langchain_community.vectorstores import FAISS\n",
    "from uuid import uuid4\n",
    "\n",
    "# OpenAI 임베딩 모델 초기화\n",
    "embeddings = OpenAIEmbeddings(model=\"text-embedding-ada-002\")\n",
    "\n",
    "# 문서 별 고유 ID 생성\n",
    "uuids1 = [f\"docs_{i+1}\" for i in range(len(summarized_docs))]\n",
    "uuids2 = [f\"docs_{i+1}\" for i in range(len(docs_rate))]\n",
    "\n",
    "# FAISS 벡터 스토어 생성\n",
    "vector_store_situation = FAISS.from_documents(\n",
    "    documents=summarized_docs, ids=uuids1, embedding=embeddings)\n",
    "vector_store_rate = FAISS.from_documents(\n",
    "    documents=docs_rate, ids=uuids2, embedding=embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 유사성 검색 리트리버 정의\n",
    "retriever1 = vector_store_situation.as_retriever(\n",
    "    search_type=\"similarity\", search_kwargs={\"k\": 1})\n",
    "retriever2 = vector_store_rate.as_retriever(\n",
    "    search_type=\"similarity\", search_kwargs={\"k\": 1})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain_core.runnables import RunnablePassthrough\n",
    "\n",
    "# 프롬프트 템플릿 정의\n",
    "contextual_prompt = ChatPromptTemplate.from_messages([\n",
    "    (\"system\", '''\n",
    "귀하는 교통사고 과실 비율을 판단하는 챗봇입니다.\n",
    "다음으로 제공되는 content1은 비슷한 사고에 관한 법원의 \"판결문\"이므로 사고 과실 비율 판단에 참고하세요.\n",
    "    또한, content2는 비슷한 사고에 관한 법원에서 인정된 \"과실 비율\"이므로, Question에 대한 과실 비율 판단에 참고하세요.\n",
    "\n",
    "\n",
    "준수해야 할 규칙:\n",
    "1. 사용자가 입력한 사고 상황을 이해한 후, 이해한 상황을 사용자에게 안내하세요.\n",
    "2. 법에 따라 판단해야 합니다.\n",
    "3. 판결 결과를 안내하면서 동시에 실제 판레도 같이 언급하세요. (되도록 content1의 법원의 판단, content2의 과실 비율 모두 언급하세요.)\n",
    "4. 판단이 올바르지 않을 가능성이 있으므로 전문가와 상의하여 보다 상세하고 신뢰할 수 있는 판단을 내릴 수 있도록 안내해 주시기 바랍니다.\n",
    "5. 판단을 내려야 할 상황에서 사용자의 입장이 불확실하다면 반드시 사용자에게 확인하세요.\n",
    "6. 주어진 상황에 관련된 법률에 대한 정보가 없다면 모른다고 대답하세요.\n",
    "7. 만일 content2의 사고 상황이 입력된 사고 상황과 유사하지 않다고 판단된다면, 관련 사례가 없음을 안내한 뒤 content1의 판결문을 참고해 과실 비율을 판단하세요.\n",
    "8. 응답을 시작할 때, 사고 상황을 겪은 사용자를 위로해주는 말로 대화를 시작하세요.\n",
    "\n",
    "주의할 규칙:\n",
    "1. 사고 상황에 대해 정리할 때에는 반드시 question의 내용으로만 정리하세요.\n",
    "2. 과실 비율에 대해 판단 할 때에는 기본적으로 content1과 content2의 정보 모두 \"참고\"하세요. (상황이 유사하지 않은 경우, 정보 없는 경우와 같은 부득이한 경우 제외)\n",
    "\n",
    "예시 응답:\n",
    "- \"제공된 사고 상황에서 귀하께선 어떠한 입장이십니까?\"\n",
    "- \"사고 상황 : 고속도로에서 갑작스럽게 후진으로 인한 사고\n",
    "\n",
    "    가능한 과실 비율 : 귀하의 경우에는 고속도로에서 갑작스럽게 후진하셨으므로 과실 비율은 1 : 9로 귀하가 최대 1,000,000원의 합의금을 내야할 수 있습니다.\n",
    "\n",
    "    실제 판례 : [상황] 고속도로에서의 후진으로 인한 사고 [청구인의 과실 비율] 10% [피청구인의 과실 비율] 90%\"\n",
    "\n",
    "\n",
    "- \"죄송합니다. 사고와 관련된 법률에 대한 정보가 없기 때문에 판단이 불가능합니다.\"\n",
    "    \n",
    "응답 형태:\n",
    "    \n",
    "    '''),\n",
    "    (\"user\", \"Context1: {context1}\\\\n\\\\Context2: {context2}\\\\n\\\\nQuestion: {question}\")\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.chains import LLMChain\n",
    "\n",
    "\n",
    "class SimplePassThrough:\n",
    "    def invoke(self, inputs, **kwargs):\n",
    "        return inputs\n",
    "\n",
    "\n",
    "class ContextToPrompt:\n",
    "    def __init__(self, prompt_template):\n",
    "        self.prompt_template = prompt_template\n",
    "\n",
    "    def invoke(self, inputs):\n",
    "        # 문서 내용을 텍스트로 변환\n",
    "        if isinstance(inputs, list):\n",
    "            context_text = \"\\n\".join([doc.page_content for doc in inputs])\n",
    "        else:\n",
    "            context_text = inputs\n",
    "\n",
    "        # 프롬프트 템플릿에 적용\n",
    "        formatted_prompt = self.prompt_template.format_messages(\n",
    "            context=context_text,\n",
    "            question=inputs.get(\"question\", \"\")\n",
    "        )\n",
    "        return formatted_prompt\n",
    "\n",
    "# Retriever를 invoke() 메서드로 래핑하는 클래스 정의\n",
    "class RetrieverWrapper:\n",
    "    def __init__(self, retriever):\n",
    "        self.retriever = retriever\n",
    "\n",
    "    def invoke(self, inputs):\n",
    "        if isinstance(inputs, dict):\n",
    "            query = inputs.get(\"question\", \"\")\n",
    "        else:\n",
    "            query = inputs\n",
    "        # 검색 수행\n",
    "        response_docs = self.retriever.get_relevant_documents(query)\n",
    "        return response_docs\n",
    "\n",
    "# RAG 체인 구성\n",
    "rag_chain_debug = {\n",
    "    \"context1\": RetrieverWrapper(retriever1),\n",
    "    'context2': RetrieverWrapper(retriever2),\n",
    "    \"prompt\": ContextToPrompt(contextual_prompt),\n",
    "    \"llm\": model\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 비슷한 상황에서 판결된 과실 비율 문서 검색\n",
    "from difflib import SequenceMatcher\n",
    "\n",
    "def get_similarity(a, b):  # 두 문자열 간의 순서대로 일치하는 부분을 비교하여 유사도를 계산\n",
    "    return SequenceMatcher(None, a, b).ratio()  # 문자열 a와 b 간의 유사도를 계산\n",
    "\n",
    "def find_most_similar_doc(user_accident):\n",
    "    max_similarity = 0\n",
    "    best_match = None # 가장 유사한 문서 저장할 변수\n",
    "    for doc in docs_rate:\n",
    "        accident_situation = doc.page_content\n",
    "        similarity = get_similarity(user_accident, accident_situation)\n",
    "        if similarity > max_similarity:\n",
    "            max_similarity = similarity\n",
    "            best_match = doc\n",
    "    return best_match"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "========================\n"
     ]
    }
   ],
   "source": [
    "# 챗봇 구동\n",
    "query = ''\n",
    "while True:\n",
    "    print(\"========================\")\n",
    "    query = input(\"질문을 입력하세요 : \")\n",
    "\n",
    "    if query == 'stop':\n",
    "        print(\"RAG 실행을 종료합니다.\")\n",
    "        break\n",
    "\n",
    "    # 1. Retriever로 관련 문서 검색\n",
    "    response_docs = rag_chain_debug[\"context1\"].invoke({\"question\": query})\n",
    "\n",
    "    # 1-1. 관련 문서와 관련된 과실 비율 문서 검색\n",
    "    response_docs2 = find_most_similar_doc(response_docs[0].metadata['summary'].content)\n",
    "\n",
    "    # 2. 문서를 프롬프트로 변환\n",
    "    prompt_messages = contextual_prompt.format_messages(\n",
    "        context1=response_docs[0].page_content,\n",
    "        context2=response_docs2.page_content,\n",
    "        question=query\n",
    "    )\n",
    "\n",
    "    # 3. LLM으로 응답 생성\n",
    "    response = rag_chain_debug[\"llm\"].invoke(prompt_messages)\n",
    "\n",
    "    print(\"\\n답변:\")\n",
    "    print(response.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "========================\n",
      "========================\n",
      "RAG 실행을 종료합니다.\n"
     ]
    }
   ],
   "source": [
    "from difflib import SequenceMatcher\n",
    "\n",
    "def get_similarity(a, b):\n",
    "    return SequenceMatcher(None, a, b).ratio()\n",
    "\n",
    "def find_most_similar_doc(user_accident):\n",
    "    max_similarity = 0\n",
    "    best_match = None\n",
    "    for doc in docs_rate:\n",
    "        accident_situation = doc.page_content\n",
    "        similarity = get_similarity(user_accident, accident_situation)\n",
    "        if similarity > max_similarity:\n",
    "            max_similarity = similarity\n",
    "            best_match = doc\n",
    "    return best_match\n",
    "\n",
    "\n",
    "# 챗봇 구동\n",
    "query = ''\n",
    "while True:\n",
    "    print(\"========================\")\n",
    "    query = input(\"질문을 입력하세요 : \")\n",
    "\n",
    "    if query == 'stop':\n",
    "        print(\"RAG 실행을 종료합니다.\")\n",
    "        break\n",
    "\n",
    "    # 1. Retriever로 관련 문서 검색\n",
    "    response_docs = rag_chain_debug[\"context1\"].invoke({\"question\": query})\n",
    "\n",
    "    # 1-1. 관련 문서와 관련된 과실 비율 문서 검색\n",
    "    response_docs2 = find_most_similar_doc(response_docs[0].metadata['summary'].content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'상황: 편도4차선도로 3차로 직진차량과 4차로에서 3차로로 진로변경차량간 사고\\n청구인 과실 비율: 30%\\n피청구인 과실 비율: 70%\\n'"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response_docs2.page_content"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "faiss_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
