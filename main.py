from Modules.ModuleImport import *  # ëª¨ë“  ëª¨ë“ˆì„ ë¶ˆëŸ¬ì˜µë‹ˆë‹¤.
from Modules.VectorStore import *
from Modules.prompt import contextual_prompt
from Modules.ContextToPrompt import ContextToPrompt
from Modules.RetrieverWrapper import RetrieverWrapper
import Modules.Speech as Speech

load_dotenv()
client = OpenAI(api_key=os.environ['OPENAI_API_KEY'])
now_dir = os.getcwd()
chat_model = ChatOpenAI(model="gpt-4o-mini")

# ì‹¤ì‹œê°„ ìŠ¤íŠ¸ë¦¬ë°ì„ ì§€ì›í•˜ëŠ” ëª¨ë¸ ì„¤ì •
# mode = openai.ChatCompletion  # OpenAIì˜ ChatCompletionì„ ì‚¬ìš©

st.title("êµí†µì‚¬ê³  ê³¼ì‹¤ ë¹„ìœ¨ ì±—ë´‡")

placeholder = st.empty()

class SimplePassThrough:
    def invoke(self, inputs, **kwargs):
        return inputs


def find_most_similar_doc(user_accident):
    """
    ì‚¬ìš©ìê°€ ì œê³µí•œ ì‚¬ê³  ì •ë³´ì™€ ê°€ì¥ ìœ ì‚¬í•œ ë¬¸ì„œë¥¼ FAISS ë²¡í„° ìŠ¤í† ì–´ì—ì„œ ê²€ìƒ‰í•©ë‹ˆë‹¤.

    Args:
        user_accident (str): ì‚¬ìš©ìê°€ ì…ë ¥í•œ ì‚¬ê³  ìƒí™© í…ìŠ¤íŠ¸.
        vector_store (FAISS): FAISS ë²¡í„° ìŠ¤í† ì–´ ê°ì²´.
        embeddings (OpenAIEmbeddings): ì„ë² ë”© ëª¨ë¸ ê°ì²´.

    Returns:
        dict: ê°€ì¥ ìœ ì‚¬í•œ ë¬¸ì„œì˜ ì •ë³´ (í…ìŠ¤íŠ¸ì™€ ë©”íƒ€ë°ì´í„°).
    """
    # ì‚¬ìš©ì ì…ë ¥ í…ìŠ¤íŠ¸ì˜ ì„ë² ë”© ê³„ì‚°
    query_embedding = embeddings.embed_query(user_accident)

    # ë²¡í„° DBì—ì„œ ìœ ì‚¬í•œ ë¬¸ì„œ ê²€ìƒ‰
    search_results = vector_store_rate.similarity_search_by_vector(
        query_embedding, k=1)

    # ê²°ê³¼ ë°˜í™˜ (ê°€ì¥ ìœ ì‚¬í•œ ë¬¸ì„œ 1ê°œ)
    if search_results:
        return search_results[0]  # ì²« ë²ˆì§¸ ê²°ê³¼ ë°˜í™˜
    else:
        return None  # ê²€ìƒ‰ ê²°ê³¼ê°€ ì—†ì„ ê²½ìš°

def init():
    # ê²½ë¡œê°€ ì—†ìœ¼ë©´ ìƒì„±
    if not os.path.exists("History"):
        os.makedirs("History")

    if "openai_model" not in st.session_state:
        st.session_state["openai_model"] = "gpt-4o-mini"
    if "messages" not in st.session_state:  # ì…ë ¥ê°’ì— ëŒ€í•œ ë©”ì‹œì§€
        st.session_state["messages"] = []
    if "active" not in st.session_state:    # ì„ íƒí•œ ëŒ€í™”ë°©
        st.session_state["active"] = ""
    if "side_data" not in st.session_state: # ì‚¬ì´ë“œë°”ì— í‘œì‹œí•˜ê¸°ìœ„í•œ ë°ì´í„°
        st.session_state["side_data"] = []
    if 'rerun' not in st.session_state:
        st.session_state.rerun = False

    # ëŒ€í™”ë‚´ì—­ ë¶ˆëŸ¬ì˜¤ê¸° ìœ„í•œ ë°ì´í„° ì´ˆê¸°í™”
    if os.path.isdir(now_dir + "/History"):
        prompt_file = os.listdir(now_dir + "/History")

        prompt_file = sorted(prompt_file, key=lambda x: int(x.split('.')[0].replace("history", "")), reverse=True)

        if len(prompt_file) > 0 and len(st.session_state.side_data) == 0:
            for file in prompt_file:
                with open(now_dir + "/History/" + file, 'r', encoding='UTF8') as f:
                    json_data = json.load(f)
                    side_title = json_data[0]["content"][0:10]
                    st.session_state.side_data.append({side_title:file})
init()

# ì‚¬ì´ë“œë°”
with st.sidebar:
    # ëŒ€í™”ë°© ì¶”ê°€
    if st.button("ìƒˆë¡œìš´ ë°©", type="primary"):
        st.session_state["messages"] = []
        st.session_state["active"] = ""

    st.title('Chat Rooms')
    sidebar_placeholder = st.sidebar.empty() # ì‚¬ì´ë“œë°”ì— ë‹¤ë¥¸ ìš”ì†Œ ì¶”ê°€ì‹œí‚¤ê¸° ìœ„í•¨        
    for i, room in enumerate(st.session_state.side_data):
        for room_name, file_name in room.items():
            cols = st.columns([4, 1])  # ë²„íŠ¼ê³¼ ì‘ì—… ë²„íŠ¼ì„ ë‚˜ëˆ„ê¸° ìœ„í•´ ì»¬ëŸ¼ ì‚¬ìš©
            with cols[0]:
                # type - ì„ íƒëœ ë²„íŠ¼ ë‹¤ë¥¸ íƒ€ì…ìœ¼ë¡œ í‘œì‹œ (ë³´ë¥˜)
                if st.button(room_name, key=f"{room_name}_{file_name}{i}"):  # ê° ëŒ€í™”ë°© ì´ë¦„ì„ ë²„íŠ¼ìœ¼ë¡œ ì¶œë ¥
                    st.session_state["messages"] = []
                    st.session_state["active"] = file_name
                    with placeholder.container():
                        with open(os.path.join(now_dir, "History", file_name), 'r', encoding='UTF8') as f:
                            json_data = json.load(f)
                            for message in json_data:
                                st.session_state.messages.append({"role":message["role"], "content":message["content"]})
                                with st.chat_message(message["role"]):
                                    st.write(message["content"])
            with cols[1]:
                if st.button("ğŸ—‘ï¸", key=f"delete_{room_name}_{i}"):
                    # ì‚­ì œ ë¡œì§
                    file_path = os.path.join("History", file_name)
                    if os.path.exists(file_path):
                        os.remove(file_path)
                    del st.session_state["side_data"][i]

                    if file_name == st.session_state["active"]:
                        st.session_state["messages"] = []
                        st.session_state["active"] = ""

                    st.session_state["rerun"] = True

if st.session_state["rerun"]:
    print("rerun")
    st.session_state["rerun"] = False
    st.rerun()

# ì±„íŒ… ë‚´ì—­ session_state ì €ì¥
def session_save(data):
    now_dir = os.getcwd()
    history_dir = now_dir + "/History/"
    # History í´ë”ì— íŒŒì¼ì´ ìˆëŠ”ì§€ í™•ì¸
    if os.path.isdir(history_dir):
        prompt_file = os.listdir(history_dir)

        # ë§ˆì§€ë§‰ íŒŒì¼ì„ ê¸°ì¤€ìœ¼ë¡œ ë„˜ë²„ë§
        sorted_file_list = natsort.natsorted(prompt_file)
        if len(sorted_file_list) > 0:
            last_file = sorted_file_list[len(sorted_file_list)-1].split(".")[0]
            file_cnt = int(last_file.replace("history", "")) + 1
        else:
            file_cnt = 1

        file_name = "history" + str(file_cnt) + ".json"

        active = st.session_state.active
        active_file = now_dir + "/History/" + active 

        # ì²« ì§ˆë¬¸ - active ê°’ ì—†ìŒ - dumpë¡œ ìƒì„±
        if active == "":
            with open(history_dir + file_name, 'w', encoding='UTF8') as f:
                json.dump([data], f)

                room_name = data["content"][0:10]
                st.session_state["active"] = file_name
                st.session_state.side_data.insert(0,{room_name:file_name})
                
                with sidebar_placeholder.container():
                    button_key = f"{room_name}_{file_name}{len(st.session_state.side_data)}"  
                    # ë™ì ìœ¼ë¡œ ë²„íŠ¼ ì¶”ê°€ì‹œ - í´ë¦­ì´ë²¤íŠ¸ ë¹„ì •ìƒ ì‘ë™ - (ë³´ë¥˜)
                    if st.button(room_name, key=button_key):  # ê° ëŒ€í™”ë°© ì´ë¦„ì„ ë²„íŠ¼ìœ¼ë¡œ ì¶œë ¥
                        st.session_state["rerun"] = True
                        print("new btn")
        # ë‘ë²ˆì§¸ëŠ” - session_state ê°’ ìˆìŒ - update
        elif os.path.isfile(active_file):
            with open(active_file, 'r', encoding='UTF8') as f:
                try:
                    # ê¸°ì¡´ ëŒ€í™” ë¶ˆëŸ¬ì˜¤ê¸°
                    json_data = json.load(f)
                    if not isinstance(json_data, list):
                        json_data = []  # íŒŒì¼ì— ë¦¬ìŠ¤íŠ¸ê°€ ì—†ìœ¼ë©´ ì´ˆê¸°í™”
                except json.JSONDecodeError:
                    json_data = []  # íŒŒì¼ì´ ë¹„ì–´ìˆìœ¼ë©´ ì´ˆê¸°í™”
                    
                json_data.append(data)
            with open(active_file, 'w', encoding='UTF8') as f:
                json.dump(json_data, f)

def make_rag_chain(query):
        # RAG ì²´ì¸ ì •ì˜
    rag_chain_debug = {
        "context": RetrieverWrapper(retriever),
        "context1": RetrieverWrapper(retriever1),
        'context2': RetrieverWrapper(retriever2),
        "prompt": ContextToPrompt(contextual_prompt),
        "llm": chat_model  # modeëŠ” ì´ì œ OpenAIì˜ ChatCompletion ê°ì²´
    }

    # 1. ê²€ìƒ‰ ë‹¨ê³„: context, context1, context2ë¡œë¶€í„° ê´€ë ¨ ì •ë³´ ê²€ìƒ‰
    response_docs = rag_chain_debug["context"].invoke({"question": query})
    response_docs1 = rag_chain_debug["context1"].invoke({"question": query})
    response_docs2 = find_most_similar_doc(
        response_docs1[0].metadata['summary'].content)

    # 'contextual_prompt'ë¥¼ ì‚¬ìš©í•˜ì—¬ í”„ë¡¬í”„íŠ¸ë¥¼ ìƒì„±í•©ë‹ˆë‹¤.
    prompt_messages = contextual_prompt.format_messages(
        context=response_docs,  # ê²€ìƒ‰ëœ context ë°ì´í„°
        context1=response_docs1,  # ê²€ìƒ‰ëœ context1 ë°ì´í„°
        context2=response_docs2,  # ê²€ìƒ‰ëœ context2 ë°ì´í„°
        question=query  # ì‚¬ìš©ìì˜ ì§ˆë¬¸
    )
    return prompt_messages

def chatbot(query, isVoice):
    # ê¸°ë³¸ ë©”ì‹œì§€ í™”ë©´ì— í‘œì‹œ
    for message in st.session_state["messages"]:
        with st.chat_message(message["role"]):
            st.write(message["content"])

    data = {"role": "user", "content": query}
    st.session_state.messages.append(data)
    session_save(data)

    with st.chat_message("user"):  # ì‚¬ìš©ì ì±„íŒ… í‘œì‹œ
        st.write(query)
    
    # ë©”ì‹œì§€ë¥¼ 'role'ê³¼ 'content'ë¡œ ë³€í™˜í•˜ì—¬ ì „ë‹¬
    with st.chat_message("assistant"):  # ë‹µë³€ ì±„íŒ… í‘œì‹œ - stream ì‹¤ì‹œê°„ ì±„íŒ…
        prompt_message = make_rag_chain(query)
        llm_response = chat_model.invoke(prompt_message)
        response = llm_response.content
        print(response)
        st.write(response)

        # stream = client.chat.completions.create(
        #     model=st.session_state["openai_model"],
        #     messages = [
        #         {"role": m["role"], "content": m["content"]}
        #         for m in st.session_state.messages
        #     ],
        #     stream=True,
        # )
        # response = st.write_stream(stream)

        data = {"role":"assistant", "content":response}
        st.session_state.messages.append({"role":"assistant", "content":response})
        
        session_save(data)

        if isVoice:     # isVoice íŒŒë¼ë¯¸í„°ì— ë”°ë¼ ì½ê¸°
            Speech.text_to_speech(response)

if st.button("ë§ˆì´í¬"):             # ë§ˆì´í¬ ì…ë ¥ì‹œ ë³´ì´ìŠ¤ ì¬ìƒ
    user_input = Speech.get_audio_input()
    if user_input is not None:
        chatbot(user_input, True)

if query := st.chat_input("ë©”ì‹œì§€ë¥¼ ì…ë ¥í•´ì£¼ì„¸ìš” "):        # ì±„íŒ… ì…ë ¥ì‹œ
    chatbot(query, False)
